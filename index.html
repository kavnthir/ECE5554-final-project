<!DOCTYPE html>

<html lang="en">

    <head>
        <meta charset="UTF-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel ="stylesheet "href="./main.css" type="text/css">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
		<!-- Webpage Title -->
        <title>ECE5554 Course Project</title> 
    </head>

    <body>

		<div class="page-header">
			<div class="text-left main" style="margin-top: 30px;">
				<h1> <strong>Infared Object Detection</strong> </h1>
				<h3> <strong> Alex Downey, Aaron Wadhwa, Kavin Thirukonda </strong> </h3> 
				<h4> Fall 2022 ECE 4554/5554 Computer Vision: Course Project </h4>
				<h4> Virginia Tech </h4>
			</div>
		</div>

		<div class="main" style="margin-bottom: 125px;">
			<!--

			<h2> Abstract </h2>
			abstract
			<br><br>
			<h2> Teaser Figures </h2>
			<div class="container-fluid text-center" style="padding: 15px;">
				<img src="https://ih1.redbubble.net/image.1395136242.8341/st,small,200x200-pad,220x220,f8f8f8.jpg">
				<img src="https://ih1.redbubble.net/image.1395136242.8341/st,small,200x200-pad,220x220,f8f8f8.jpg">
				<img src="https://ih1.redbubble.net/image.1395136242.8341/st,small,200x200-pad,220x220,f8f8f8.jpg">
				<img src="https://ih1.redbubble.net/image.1395136242.8341/st,small,200x200-pad,220x220,f8f8f8.jpg">
			</div>
			Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Erat imperdiet sed euismod nisi porta lorem. Lorem sed risus ultricies tristique nulla aliquet enim tortor at. Blandit turpis cursus in hac habitasse platea. Ornare arcu dui vivamus arcu. Nulla facilisi cras fermentum odio eu feugiat. Amet tellus cras adipiscing enim eu turpis egestas pretium aenean. Sem et tortor consequat id porta nibh venenatis cras sed. Consectetur adipiscing elit duis tristique sollicitudin nibh. Velit dignissim sodales ut eu. Leo vel orci porta non pulvinar. Bibendum arcu vitae elementum curabitur vitae nunc sed velit dignissim. Sit amet facilisis magna etiam tempor orci. Sagittis purus sit amet volutpat consequat mauris nunc congue nisi. Aenean euismod elementum nisi quis eleifend. Sit amet dictum sit amet justo donec. Sed felis eget velit aliquet sagittis id consectetur. Arcu cursus euismod quis viverra nibh. Ut ornare lectus sit amet est placerat.
			<br><br>

			-->

			<h2> Introduction </h2>
			Thermal imaging is the process of developing a heat-mapped image based on the surrounding locations. There are various applications for it, however, its primary benefits lie in visualizing an environment with low visibility – whether it be fog, smoke, or any other non-solid barrier. Understanding an environment with poor visibility can allow for improved safety in various applications including railway operation. The goal of this project is to develop a model that can accurately detect common objects including people, bikes, cars, trains, and traffic lights in a given thermal image through image formation, edge detection, and other concepts learned both in class and throughout our courses at Virginia Tech. Previous work in this subject area often references the You Only Learn Once or YOLO model based on convolutional neural networks. Although we will use similar concepts and apply our model only to infrared images, we still plan to build our model with outlines based on this existing framework.
			<h2> Approach </h2>
			The backbone of our approach will leverage a Convolutional Neural Network (CNN) with fully connected layers to identify objects within an IR context.  In the forward stage, an input image will be convoluted with a series of feature kernels through successive stages before being flattened into a vector and run through a fully connected network.  Gradient descent will be used to tune the weights in the model to minimize error during training.  Research concerning IR object detection strongly favors the “You Only Look Once” (YOLO) architecture to produce bounding boxes and classifications for provided data.  The YOLOv5 framework is one of the more recent, stable versions of YOLO that has a fair degree of literature and documentation concerning its use.  YOLO also hosts several internal tools and features that greatly facilitate the data preparation, training, and evaluation processes, giving us the flexibility to experiment with different parameters with confidence.  Not only will YOLO identify regions of interest in the data, but it will classify these found objects as well
			There will be elements of preprocessing depending on the quality of our data and the format of its annotations.  As we continue to better understand our data, we will develop scripts to make the annotation format compatible with YOLO standards, adjust images to filter noise, alter size, experiment with different processing methods, etc.  The dataset we are using also contains RGB images as well, if time permits we may develop an ensemble model to ingest IR and RGB inputs.  From initial inspection, it seems like the RGB images are not perfectly aligned with the IR inputs, so we will most likely need to employ some alignment techniques if we decide to pursue that route.
			<div class="container-fluid text-center" style="padding: 15px;">
				<img src="https://cdn.discordapp.com/attachments/463193265416699915/1030668823843573850/unknown.png" style="width: 80%">
				<p>Figure 1. CNN and YOLO architecture</p>
			</div>

			<h2> Experiments and results </h2>
			For this project, we will be using an open-source thermal dataset for algorithm training by Teledyne FLIR. The dataset contains 26,442 image frames with over 520,000 annotations with the following 15 objects that were detected and labeled: person, bike, car, motorcycle, bus, train, truck, traffic light, fire hydrant, street sign, dog, skateboard, stroller, scooter, & other vehicle. Out of these image frames, there are around 9,000 training frames, and 9,000 validation frames as well. This will enable us to develop testing accuracies that validate the object de The file types include TIFF and JPEG for the thermal and RGB images, and JSON for the annotations. Figure 2 shows an example of one of the thermal images from the dataset. As described earlier, the images have annotations with bounding boxes and the detected items such as person and car. In addition, the reasoning behind not collecting our own data stems from the high-cost of the camera required to take quality thermal images. As shown by Figure 3, the Teledyne FLIR camera was the one that produced the images that we are using as our training and testing sets.  As mentioned in our approach, we will be using the YOLOv5 framework to train and evaluate our model.  We will be developing our own scripts to format the dataset annotations and prepare the data as inputs.  For this project, success will be defined as a model that can correctly identify and classify objects of interest from provided IR inputs.  Since the FLIR dataset contains RGB equivalents as well, we will also train a model on RGB inputs and compare the two models under a variety of environmental conditions (time of day, weather, etc.).  Success will also be evaluated under the IR model’s ability to perform better than its RGB counterpart in low-visibility conditions.  Quantitative metric for success will be pending until our team has a better understanding of our dataset, but the results (and successes) of our project will be demonstrable from a qualitative point of view.  With time permitting, we would also like to create an ensemble model of both RGB and IR data, that would benefit from the strengths of both models.  We may also decide to include additional classification categories in our annotations depending on the success of the project.
			<br><br>
			<div class="container-fluid text-center" style="padding: 15px;">
				<img src="https://cdn.discordapp.com/attachments/463193265416699915/1030670805308276836/unknown.png" style="width: 60%">
				<p>Figure 2. Thermal Image Example from FLIR Dataset</p>
				<img src="https://cdn.discordapp.com/attachments/463193265416699915/1030671255877206066/unknown.png" style="width: 60%">
				<p>Figure 3. Teledyne FLIR Tau 2 Thermal Camera</p>
			</div>
			<!--

			<h2> Qualitative Results </h2>
			Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Varius duis at consectetur lorem donec massa sapien. Interdum varius sit amet mattis vulputate enim. Imperdiet dui accumsan sit amet. Velit aliquet sagittis id consectetur purus. Sagittis id consectetur purus ut faucibus pulvinar elementum integer enim. Tristique nulla aliquet enim tortor at auctor urna nunc. Ultricies leo integer malesuada nunc. Orci sagittis eu volutpat odio facilisis mauris sit. Cras semper auctor neque vitae tempus quam pellentesque. Bibendum est ultricies integer quis auctor.
			<h2> Conclusion </h2>
			Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Varius duis at consectetur lorem donec massa sapien. Interdum varius sit amet mattis vulputate enim. Imperdiet dui accumsan sit amet. Velit aliquet sagittis id consectetur purus. Sagittis id consectetur purus ut faucibus pulvinar elementum integer enim. Tristique nulla aliquet enim tortor at auctor urna nunc. Ultricies leo integer malesuada nunc. Orci sagittis eu volutpat odio facilisis mauris sit. Cras semper auctor neque vitae tempus quam pellentesque. Bibendum est ultricies integer quis auctor.

			-->
			<h2> References </h2>
			<ul>
				<li> <a href="https://www.flir.com/discover/traffic/public-transportation/thermal-imaging-for-safety-and-efficiency-in-public-transportation/#:~:text=Based%20on%20temperature%20differences%20between,people%20walking%20in%20tunnels%2C%20etc.">https://www.flir.com/discover/traffic/public-transportation/thermal-imaging-for-safety-and-efficiency-in-public-transportation/#:~:text=Based%20on%20temperature%20differences%20between,people%20walking%20in%20tunnels%2C%20etc.</a></li>
				<li> <a href="https://www.researchgate.net/publication/333360405_Human_Detection_in_Thermal_Imaging_Using_YOLO">https://www.researchgate.net/publication/333360405_Human_Detection_in_Thermal_Imaging_Using_YOLO</a></li>
				<li> <a href="https://www.sciencedirect.com/science/article/pii/S1569843222001145">https://www.sciencedirect.com/science/article/pii/S1569843222001145 </a></li>
				<li> <a href="https://github.com/ultralytics/yolov5"> https://github.com/ultralytics/yolov5 </a></li>
			</ul>
		</div>

    </body>

	<footer class="footer">
		<div class="feet text-muted">
			Ⓒ Alex Downey, Aaron Wadhwa, Kavin Thirukonda
		</div>
	</footer>

</html>
